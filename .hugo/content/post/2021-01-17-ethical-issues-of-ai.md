---
title: Ethical issues of Artificial Intelligence
date: "2020-02-17T00:00:00+00:00"
draft: false
tags: ["ethics", "artificial intelligence"]
---

# Introduction
There is a [mooc in the University of Helsinki about
the ethics of artificial intelligenice](https://ethics-of-ai.mooc.fi/). I just started it and it's great.

# The triumph of technicism
Us engineers tend to think that there is no problem (technical or else)
that cannot be resolved by technological means.
That's called *technicism*.

Usually that's right for small-scale problems or systems, but in the
case of artificial intelligence, or being more precise machine learning
that's not true.

# The machine is always right?
A machine learning algorithm does not act in a certain way because
of how it's been developed, but it acts in a certain way because
of the data it's been given. If the algorithm receives biased data
the algorithm will be surely biased. Of course we can argue that
there are some algorithms that are better than others but the main
issue is to have a big-enough big-quality dataset.

# Computers rule the world
In a world were corporations can access to/obtain big datasets,
and are using massively machine learning to take decissions,
we have to make sure there is no harm done to the society.
As AI is more ubiquitous we have to make sure a minimal rules
are laid out in the field to avoid discrimination, to keep
users' privacy, and other issues that are arising from time to time.

# Conclusion: but is not my fault!
Again, us as engineers and scientist cannot defend ourselves
with the argument of "blame the doer, not the creator".
A new power, as powerful as the atom bomb is now among us,
and we have to protect the human race. New laws should be
made, but we cannot rely only on them and must **made sure
our creations make no harm by action or omission**.